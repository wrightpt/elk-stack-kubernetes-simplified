Directory Structure:
elk-stack-repo/
│   ├── elasticsearch-git.yaml
│   ├── traefik-app.yaml
│   ├── elk-ingress-routes.yaml
│   ├── kibana-git.yaml
│   ├── logstash-git.yaml
│   ├── traefik-git.yaml
argocd/
│   ├── setup/
│   ├── │   ├── argocd-installation.yaml
│   ├── applications/
│   ├── │   ├── logstash.yaml
│   ├── │   ├── metallb.yaml
│   ├── │   ├── elasticsearch.yaml
│   ├── │   ├── kibana.yaml
│   ├── │   ├── traefik.yaml
│   ├── │   ├── metallb-config.yaml
.git/
│   ├── logs/
│   │   ├── refs/
│   │   │   ├── heads/
│   │   │   ├── remotes/
│   │   │   │   ├── origin/
│   ├── hooks/
│   ├── info/
│   ├── objects/
│   │   ├── 7a/
│   │   ├── e1/
│   │   ├── ab/
│   │   ├── 3c/
│   │   ├── 32/
│   │   ├── pack/
│   │   ├── b3/
│   │   ├── ca/
│   │   ├── fe/
│   │   ├── 88/
│   │   ├── 79/
│   │   ├── 20/
│   │   ├── 8d/
│   │   ├── 05/
│   │   ├── 0a/
│   │   ├── e2/
│   │   ├── 0e/
│   │   ├── 24/
│   │   ├── 6e/
│   │   ├── 8c/
│   │   ├── ef/
│   │   ├── 97/
│   │   ├── 3b/
│   │   ├── d7/
│   │   ├── b8/
│   │   ├── 11/
│   │   ├── f8/
│   │   ├── 42/
│   │   ├── 6c/
│   │   ├── 39/
│   │   ├── 38/
│   │   ├── 84/
│   │   ├── 81/
│   │   ├── 58/
│   │   ├── 91/
│   │   ├── 60/
│   │   ├── 34/
│   │   ├── f9/
│   │   ├── ac/
│   │   ├── b9/
│   │   ├── 36/
│   │   ├── 0c/
│   │   ├── 3a/
│   │   ├── e6/
│   │   ├── 94/
│   │   ├── 16/
│   │   ├── 51/
│   │   ├── 78/
│   │   ├── 5e/
│   │   ├── 92/
│   │   ├── b2/
│   │   ├── e4/
│   │   ├── 09/
│   │   ├── 9a/
│   │   ├── a3/
│   │   ├── da/
│   │   ├── 01/
│   │   ├── fd/
│   │   ├── 07/
│   │   ├── 41/
│   │   ├── 3f/
│   │   ├── 27/
│   │   ├── c4/
│   │   ├── ed/
│   │   ├── 2a/
│   │   ├── 3d/
│   │   ├── 35/
│   │   ├── 4b/
│   │   ├── 98/
│   │   ├── a2/
│   │   ├── 02/
│   │   ├── 8e/
│   │   ├── e0/
│   │   ├── 50/
│   │   ├── f1/
│   │   ├── 9e/
│   │   ├── bb/
│   │   ├── 2b/
│   │   ├── e3/
│   │   ├── 4a/
│   │   ├── d0/
│   │   ├── 87/
│   │   ├── be/
│   │   ├── 80/
│   │   ├── f7/
│   │   ├── 37/
│   │   ├── ec/
│   │   ├── 12/
│   │   ├── e8/
│   │   ├── 71/
│   │   ├── info/
│   │   ├── ad/
│   │   ├── 40/
│   │   ├── 46/
│   │   ├── 1c/
│   │   ├── 86/
│   │   ├── 1e/
│   │   ├── 31/
│   │   ├── 5b/
│   │   ├── c9/
│   │   ├── 7f/
│   │   ├── f0/
│   │   ├── c0/
│   │   ├── 99/
│   │   ├── 54/
│   │   ├── 63/
│   │   ├── eb/
│   │   ├── 76/
│   │   ├── 56/
│   │   ├── 06/
│   │   ├── 9d/
│   │   ├── c2/
│   │   ├── dd/
│   │   ├── ce/
│   │   ├── 0b/
│   │   ├── b6/
│   │   ├── 74/
│   │   ├── 3e/
│   │   ├── 6f/
│   ├── branches/
│   ├── refs/
│   │   ├── heads/
│   │   ├── tags/
│   │   ├── remotes/
│   │   │   ├── origin/
docker/
│   ├── elasticsearch/
│   ├── │   ├── Dockerfile
│   ├── traefik/
│   ├── │   ├── Dockerfile
│   ├── logstash/
│   ├── │   ├── Dockerfile
│   ├── kibana/
│   ├── │   ├── Dockerfile
helm/
│   ├── elasticsearch/
│   ├── │   ├── values.yaml
│   ├── │   ├── Chart.yaml
│   ├── traefik/
│   ├── │   ├── values.yaml
│   ├── │   ├── Chart.yaml
│   ├── logstash/
│   ├── │   ├── values.yaml
│   ├── │   ├── Chart.yaml
│   ├── kibana/
│   ├── │   ├── values.yaml
│   ├── │   ├── Chart.yaml

=== File: elasticsearch-git.yaml ===
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: elasticsearch
  namespace: argocd
spec:
  project: default
  source:
    repoURL: git@github.com:wrightpt/elk-stack-kubernetes-simplified.git
    targetRevision: main
    path: helm
    helm:
      valueFiles:
        - elasticsearch-values.yaml
  destination:
    server: https://kubernetes.default.svc
    namespace: elk
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true


=== File: traefik-app.yaml ===
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"argoproj.io/v1alpha1","kind":"Application","metadata":{"annotations":{},"labels":{"app.kubernetes.io/instance":"metallb"},"name":"traefik","namespace":"argocd"},"spec":{"destination":{"namespace":"traefik","server":"https://kubernetes.default.svc"},"project":"default","source":{"chart":"traefik","helm":{"valueFiles":["values.yaml"]},"repoURL":"https://helm.traefik.io/traefik","targetRevision":"10.24.0"},"syncPolicy":{"automated":{"prune":true,"selfHeal":true},"syncOptions":["CreateNamespace=true"]}}}
  creationTimestamp: "2025-03-01T23:49:47Z"
  generation: 1063
  labels:
    app.kubernetes.io/instance: metallb
  managedFields:
  - apiVersion: argoproj.io/v1alpha1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations: {}
      f:spec:
        .: {}
        f:destination:
          .: {}
          f:namespace: {}
          f:server: {}
        f:project: {}
        f:source:
          .: {}
          f:helm: {}
        f:syncPolicy:
          .: {}
          f:automated:
            .: {}
            f:prune: {}
            f:selfHeal: {}
          f:syncOptions: {}
    manager: kubectl-client-side-apply
    operation: Update
    time: "2025-03-01T23:49:47Z"
  - apiVersion: argoproj.io/v1alpha1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          f:kubectl.kubernetes.io/last-applied-configuration: {}
        f:labels:
          .: {}
          f:app.kubernetes.io/instance: {}
      f:spec:
        f:source:
          f:chart: {}
          f:helm:
            f:valueFiles: {}
          f:repoURL: {}
          f:targetRevision: {}
    manager: argocd-controller
    operation: Update
    time: "2025-03-02T03:55:59Z"
  - apiVersion: argoproj.io/v1alpha1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        .: {}
        f:controllerNamespace: {}
        f:health:
          .: {}
          f:lastTransitionTime: {}
          f:status: {}
        f:history: {}
        f:operationState:
          .: {}
          f:finishedAt: {}
          f:message: {}
          f:operation:
            .: {}
            f:initiatedBy:
              .: {}
              f:username: {}
            f:retry: {}
            f:sync:
              .: {}
              f:revision: {}
              f:syncOptions: {}
              f:syncStrategy:
                .: {}
                f:hook:
                  .: {}
                  f:force: {}
          f:phase: {}
          f:startedAt: {}
          f:syncResult:
            .: {}
            f:resources: {}
            f:revision: {}
            f:source:
              .: {}
              f:chart: {}
              f:helm:
                .: {}
                f:valueFiles: {}
              f:repoURL: {}
              f:targetRevision: {}
        f:reconciledAt: {}
        f:resources: {}
        f:sourceType: {}
        f:summary:
          .: {}
          f:images: {}
        f:sync:
          .: {}
          f:comparedTo:
            .: {}
            f:destination:
              .: {}
              f:namespace: {}
              f:server: {}
            f:source:
              .: {}
              f:chart: {}
              f:helm:
                .: {}
                f:valueFiles: {}
              f:repoURL: {}
              f:targetRevision: {}
          f:revision: {}
          f:status: {}
    manager: argocd-application-controller
    operation: Update
    time: "2025-03-03T02:15:39Z"
  - apiVersion: argoproj.io/v1alpha1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        f:sourceHydrator: {}
    manager: argocd-server
    operation: Update
    time: "2025-03-03T02:15:39Z"
  name: traefik
  namespace: argocd
  resourceVersion: "177059"
  uid: 0bd85af7-0696-4164-b788-e1cbd2599f64
spec:
  destination:
    namespace: traefik
    server: https://kubernetes.default.svc
  project: default
  source:
    repoURL: git@github.com:wrightpt/elk-stack-kubernetes-simplified.git
    targetRevision: main
    path: helm/traefik
    helm:
      valueFiles:
      - values.yaml
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
status:
  controllerNamespace: argocd
  health:
    lastTransitionTime: "2025-03-03T02:11:36Z"
    status: Healthy
  history:
  - deployStartedAt: "2025-03-03T00:20:41Z"
    deployedAt: "2025-03-03T00:20:44Z"
    id: 13
    initiatedBy:
      username: admin
    revision: 10.24.0
    source:
      chart: traefik
      helm:
        valueFiles:
        - values.yaml
      repoURL: https://helm.traefik.io/traefik
      targetRevision: 10.24.0
  - deployStartedAt: "2025-03-03T00:50:29Z"
    deployedAt: "2025-03-03T00:50:32Z"
    id: 14
    initiatedBy:
      username: admin
    revision: 10.24.0
    source:
      chart: traefik
      helm:
        valueFiles:
        - values.yaml
      repoURL: https://helm.traefik.io/traefik
      targetRevision: 10.24.0
  - deployStartedAt: "2025-03-03T01:05:47Z"
    deployedAt: "2025-03-03T01:05:50Z"
    id: 15
    initiatedBy:
      username: admin
    revision: 10.24.0
    source:
      chart: traefik
      helm:
        valueFiles:
        - values.yaml
      repoURL: https://helm.traefik.io/traefik
      targetRevision: 10.24.0
  - deployStartedAt: "2025-03-03T01:06:05Z"
    deployedAt: "2025-03-03T01:06:08Z"
    id: 16
    initiatedBy:
      username: admin
    revision: 10.24.0
    source:
      chart: traefik
      helm:
        valueFiles:
        - values.yaml
      repoURL: https://helm.traefik.io/traefik
      targetRevision: 10.24.0
  - deployStartedAt: "2025-03-03T01:12:18Z"
    deployedAt: "2025-03-03T01:12:21Z"
    id: 17
    initiatedBy:
      username: admin
    revision: 10.24.0
    source:
      chart: traefik
      helm:
        valueFiles:
        - values.yaml
      repoURL: https://helm.traefik.io/traefik
      targetRevision: 10.24.0
  - deployStartedAt: "2025-03-03T01:12:27Z"
    deployedAt: "2025-03-03T01:12:30Z"
    id: 18
    initiatedBy:
      username: admin
    revision: 10.24.0
    source:
      chart: traefik
      helm:
        valueFiles:
        - values.yaml
      repoURL: https://helm.traefik.io/traefik
      targetRevision: 10.24.0
  - deployStartedAt: "2025-03-03T01:39:33Z"
    deployedAt: "2025-03-03T01:39:36Z"
    id: 19
    initiatedBy:
      username: admin
    revision: 10.24.0
    source:
      chart: traefik
      helm:
        valueFiles:
        - values.yaml
      repoURL: https://helm.traefik.io/traefik
      targetRevision: 10.24.0
  - deployStartedAt: "2025-03-03T01:39:43Z"
    deployedAt: "2025-03-03T01:39:46Z"
    id: 20
    initiatedBy:
      username: admin
    revision: 10.24.0
    source:
      chart: traefik
      helm:
        valueFiles:
        - values.yaml
      repoURL: https://helm.traefik.io/traefik
      targetRevision: 10.24.0
  - deployStartedAt: "2025-03-03T02:11:43Z"
    deployedAt: "2025-03-03T02:11:46Z"
    id: 21
    initiatedBy:
      username: admin
    revision: 10.24.0
    source:
      chart: traefik
      helm:
        valueFiles:
        - values.yaml
      repoURL: https://helm.traefik.io/traefik
      targetRevision: 10.24.0
  - deployStartedAt: "2025-03-03T02:15:35Z"
    deployedAt: "2025-03-03T02:15:38Z"
    id: 22
    initiatedBy:
      username: admin
    revision: 10.24.0
    source:
      chart: traefik
      helm:
        valueFiles:
        - values.yaml
      repoURL: https://helm.traefik.io/traefik
      targetRevision: 10.24.0
  operationState:
    finishedAt: "2025-03-03T02:15:38Z"
    message: successfully synced (no more tasks)
    operation:
      initiatedBy:
        username: admin
      retry: {}
      sync:
        revision: 10.24.0
        syncOptions:
        - CreateNamespace=true
        syncStrategy:
          hook:
            force: true
    phase: Succeeded
    startedAt: "2025-03-03T02:15:35Z"
    syncResult:
      resources:
      - group: ""
        hookPhase: Succeeded
        kind: ServiceAccount
        message: serviceaccount/traefik unchanged
        name: traefik
        namespace: traefik
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/middlewaretcps.traefik.containo.us
          configured
        name: middlewaretcps.traefik.containo.us
        namespace: traefik
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/serverstransports.traefik.containo.us
          configured
        name: serverstransports.traefik.containo.us
        namespace: traefik
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/ingressrouteudps.traefik.containo.us
          configured
        name: ingressrouteudps.traefik.containo.us
        namespace: traefik
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/ingressroutes.traefik.containo.us
          configured
        name: ingressroutes.traefik.containo.us
        namespace: traefik
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/tlsstores.traefik.containo.us
          configured
        name: tlsstores.traefik.containo.us
        namespace: traefik
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/tlsoptions.traefik.containo.us
          configured
        name: tlsoptions.traefik.containo.us
        namespace: traefik
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/ingressroutetcps.traefik.containo.us
          configured
        name: ingressroutetcps.traefik.containo.us
        namespace: traefik
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/traefikservices.traefik.containo.us
          configured
        name: traefikservices.traefik.containo.us
        namespace: traefik
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apiextensions.k8s.io
        hookPhase: Succeeded
        kind: CustomResourceDefinition
        message: customresourcedefinition.apiextensions.k8s.io/middlewares.traefik.containo.us
          configured
        name: middlewares.traefik.containo.us
        namespace: traefik
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRole
        message: clusterrole.rbac.authorization.k8s.io/traefik reconciled. clusterrole.rbac.authorization.k8s.io/traefik
          unchanged
        name: traefik
        namespace: traefik
        status: Synced
        syncPhase: Sync
        version: v1
      - group: rbac.authorization.k8s.io
        hookPhase: Succeeded
        kind: ClusterRoleBinding
        message: clusterrolebinding.rbac.authorization.k8s.io/traefik reconciled.
          clusterrolebinding.rbac.authorization.k8s.io/traefik unchanged
        name: traefik
        namespace: traefik
        status: Synced
        syncPhase: Sync
        version: v1
      - group: ""
        hookPhase: Succeeded
        kind: Service
        message: service/traefik unchanged
        name: traefik
        namespace: traefik
        status: Synced
        syncPhase: Sync
        version: v1
      - group: apps
        hookPhase: Succeeded
        kind: Deployment
        message: deployment.apps/traefik configured
        name: traefik
        namespace: traefik
        status: Synced
        syncPhase: Sync
        version: v1
      - group: traefik.containo.us
        hookPhase: Succeeded
        hookType: PostSync
        kind: IngressRoute
        message: traefik-dashboard created
        name: traefik-dashboard
        namespace: traefik
        syncPhase: PostSync
        version: v1alpha1
      revision: 10.24.0
      source:
        chart: traefik
        helm:
          valueFiles:
          - values.yaml
        repoURL: https://helm.traefik.io/traefik
        targetRevision: 10.24.0
  reconciledAt: "2025-03-03T02:15:39Z"
  resources:
  - health:
      status: Healthy
    kind: Service
    name: traefik
    namespace: traefik
    status: Synced
    version: v1
  - kind: ServiceAccount
    name: traefik
    namespace: traefik
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: ingressroutes.traefik.containo.us
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: ingressroutetcps.traefik.containo.us
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: ingressrouteudps.traefik.containo.us
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: middlewares.traefik.containo.us
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: middlewaretcps.traefik.containo.us
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: serverstransports.traefik.containo.us
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: tlsoptions.traefik.containo.us
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: tlsstores.traefik.containo.us
    status: Synced
    version: v1
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
    name: traefikservices.traefik.containo.us
    status: Synced
    version: v1
  - group: apps
    health:
      status: Healthy
    kind: Deployment
    name: traefik
    namespace: traefik
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
    name: traefik
    status: Synced
    version: v1
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
    name: traefik
    status: Synced
    version: v1
  - group: traefik.containo.us
    hook: true
    kind: IngressRoute
    name: traefik-dashboard
    namespace: traefik
    requiresPruning: true
    version: v1alpha1
  sourceHydrator: {}
  sourceType: Helm
  summary:
    images:
    - traefik:2.8.0
  sync:
    comparedTo:
      destination:
        namespace: traefik
        server: https://kubernetes.default.svc
      source:
        chart: traefik
        helm:
          valueFiles:
          - values.yaml
        repoURL: https://helm.traefik.io/traefik
        targetRevision: 10.24.0
    revision: 10.24.0
    status: Synced


=== File: elk-ingress-routes.yaml ===
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  name: elasticsearch-route
  namespace: traefik
spec:
  entryPoints:
    - websecure
  routes:
    - match: Host(`elasticsearch.1xmr.com`)
      kind: Rule
      services:
        - name: elasticsearch-master
          namespace: elk
          port: 9200
  tls:
    certResolver: letsencrypt

---
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  name: kibana-route
  namespace: traefik
spec:
  entryPoints:
    - websecure
  routes:
    - match: Host(`kibana.1xmr.com`)
      kind: Rule
      services:
        - name: kibana
          namespace: elk
          port: 5601
  tls:
    certResolver: letsencrypt

---
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  name: logstash-route
  namespace: traefik
spec:
  entryPoints:
    - websecure
  routes:
    - match: Host(`logstash.1xmr.com`)
      kind: Rule
      services:
        - name: logstash
          namespace: elk
          port: 5044
  tls:
    certResolver: letsencrypt


=== File: kibana-git.yaml ===
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: kibana
  namespace: argocd
spec:
  project: default
  source:
    repoURL: git@github.com:wrightpt/elk-stack-kubernetes-simplified.git
    targetRevision: main
    path: helm
    helm:
      valueFiles:
        - kibana-values.yaml
  destination:
    server: https://kubernetes.default.svc
    namespace: elk
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true


=== File: logstash-git.yaml ===
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: logstash
  namespace: argocd
spec:
  project: default
  source:
    repoURL: git@github.com:wrightpt/elk-stack-kubernetes-simplified.git
    targetRevision: main
    path: helm
    helm:
      valueFiles:
        - logstash-values.yaml
  destination:
    server: https://kubernetes.default.svc
    namespace: elk
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true


=== File: traefik-git.yaml ===
#/elk-stack-repo/traefik-git.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: traefik
  namespace: argocd
spec:
  project: default
  source:
    repoURL: git@github.com:wrightpt/elk-stack-kubernetes-simplified.git
    targetRevision: main
    path: helm/traefik  # Updated to point to the correct subdirectory
    helm:
      valueFiles:
        - values.yaml  # Updated to match the actual filename in the directory
  destination:
    server: https://kubernetes.default.svc
    namespace: traefik
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true


=== File: argocd/setup/argocd-installation.yaml ===
# argocd/setup/argocd-installation.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: argocd
---
# This includes the core ArgoCD installation
# When applying, use: kubectl apply -f argocd-installation.yaml -n argocd


=== File: argocd/applications/logstash.yaml ===
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: logstash
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://helm.elastic.co
    chart: logstash
    targetRevision: 7.17.3
    helm:
      valueFiles:
        - values.yaml
  destination:
    server: https://kubernetes.default.svc
    namespace: elk
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true


=== File: argocd/applications/metallb.yaml ===
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: metallb
  namespace: argocd
spec:
  project: default
  source:
    repoURL: 'git@github.com:wrightpt/elk-stack-kubernetes-simplified.git'
    targetRevision: main
    path: argocd/applications   # Adjust as needed
    directory:
      recurse: true             # If needed for scanning nested files
  destination:
    server: 'https://kubernetes.default.svc'
    namespace: metallb-system
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true



=== File: argocd/applications/elasticsearch.yaml ===
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: elasticsearch
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://helm.elastic.co
    chart: elasticsearch
    targetRevision: 7.17.3
    helm:
      valueFiles:
        - values.yaml
  destination:
    server: https://kubernetes.default.svc
    namespace: elk
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true


=== File: argocd/applications/kibana.yaml ===
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: kibana
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://helm.elastic.co
    chart: kibana
    targetRevision: 7.17.3
    helm:
      valueFiles:
        - values.yaml
  destination:
    server: https://kubernetes.default.svc
    namespace: elk
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true


=== File: argocd/applications/traefik.yaml ===
#/elk-stack-repo/argocd/applications/traefik.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: traefik
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://helm.traefik.io/traefik
    chart: traefik
    targetRevision: 10.24.0
    helm:
      valueFiles:
        - values.yaml
  destination:
    server: https://kubernetes.default.svc
    namespace: traefik
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true


=== File: argocd/applications/metallb-config.yaml ===
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: home-lan-pool
  namespace: metallb-system
spec:
  addresses:
    - 192.168.1.240-192.168.1.250
  # Set autoAssign to 'true' if you want MetalLB to automatically assign IPs 
  # from this pool to LoadBalancer Services.
  autoAssign: true

---
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: home-lan-advert
  namespace: metallb-system
spec:
  # Name of the IPAddressPool to advertise on L2
  ipAddressPools:
    - home-lan-pool



=== File: docker/elasticsearch/Dockerfile ===
FROM docker.elastic.co/elasticsearch/elasticsearch:7.17.3

# Copy custom configuration files
COPY elasticsearch.yml /usr/share/elasticsearch/config/
COPY jvm.options /usr/share/elasticsearch/config/

# Set permissions
USER root
RUN chmod 660 /usr/share/elasticsearch/config/elasticsearch.yml \
    && chmod 660 /usr/share/elasticsearch/config/jvm.options \
    && chown -R 1000:0 /usr/share/elasticsearch/config

# Switch back to elasticsearch user
USER 1000


=== File: docker/traefik/Dockerfile ===
FROM traefik:v2.9

# Copy Traefik configuration
COPY traefik.yml /etc/traefik/
COPY config.yml /etc/traefik/

# REDACTED: Sensitive content removed
RUN mkdir -p /letsencrypt


=== File: docker/logstash/Dockerfile ===
FROM docker.elastic.co/logstash/logstash:7.17.3

# Copy configuration files
COPY logstash.yml /usr/share/logstash/config/
COPY pipelines.yml /usr/share/logstash/config/
COPY jvm.options /usr/share/logstash/config/
COPY conf.d/ /usr/share/logstash/pipeline/

# Set permissions
USER root
RUN chmod 660 /usr/share/logstash/config/logstash.yml \
    && chmod 660 /usr/share/logstash/config/pipelines.yml \
    && chmod 660 /usr/share/logstash/config/jvm.options \
    && chmod -R 660 /usr/share/logstash/pipeline/ \
    && chown -R 1000:0 /usr/share/logstash/config \
    && chown -R 1000:0 /usr/share/logstash/pipeline

# Switch back to logstash user
USER 1000


=== File: docker/kibana/Dockerfile ===
FROM docker.elastic.co/kibana/kibana:7.17.3

# Copy custom configuration
COPY kibana.yml /usr/share/kibana/config/

# Set permissions
USER root
RUN chmod 660 /usr/share/kibana/config/kibana.yml \
    && chown -R 1000:0 /usr/share/kibana/config

# Switch back to kibana user
USER 1000


=== File: helm/elasticsearch/values.yaml ===
# helm/elasticsearch-values.yaml
replicas: 1  # Adjust based on your home server capacity

# Resource requests and limits
resources:
  requests:
    cpu: "500m"
    memory: "1Gi"
  limits:
    cpu: "1"
    memory: "2Gi"

# Persistence configuration
persistence:
  enabled: true
  storageClass: "local-storage"
  size: "30Gi"

# Network settings
service:
  type: ClusterIP

# Security settings
securityContext:
  enabled: true
  runAsUser: 1000
  fsGroup: 1000

# Config for ES
esConfig:
  elasticsearch.yml: |
    cluster.name: home-cluster
    discovery.type: single-node
    xpack.security.enabled: true
    xpack.security.transport.ssl.enabled: true


=== File: helm/elasticsearch/Chart.yaml ===
apiVersion: v2
name: elasticsearch
description: Elasticsearch Helm chart for Kubernetes
type: application
version: 1.0.0
appVersion: 7.17.3
dependencies:
  - name: elasticsearch
    version: 7.17.3
    repository: https://helm.elastic.co


=== File: helm/traefik/values.yaml ===
# elk-stack-repo/helm/traefik/values.yaml
# Define the service configuration for Traefik
service:
  type: LoadBalancer
  externalIPs:
    - 192.168.1.240
  ports:
    web:
      port: 80
      protocol: TCP
    websecure:
      port: 443
      protocol: TCP

# Enable the Traefik dashboard for monitoring
dashboard:
  enabled: true

# Configure an IngressRoute for the dashboard
ingressRoute:
  dashboard:
    enabled: true
    rule: "Host(`traefik.local`) && PathPrefix(`/dashboard`)"
    tls:
      certResolver: letsencrypt

# Enable Kubernetes providers to allow Traefik to discover services and ingresses
providers:
  kubernetesCRD:
    enabled: true
  kubernetesIngress:
    enabled: true

# REDACTED: Sensitive content removed
additionalArguments:
# REDACTED: Sensitive content removed
# REDACTED: Sensitive content removed
# REDACTED: Sensitive content removed
# REDACTED: Sensitive content removed
# REDACTED: Sensitive content removed
# REDACTED: Sensitive content removed
  - "--serverstransport.insecureskipverify=true"
  - "--log.level=DEBUG"

# REDACTED: Sensitive content removed
persistence:
  enabled: true
  name: traefik-certs
  accessMode: ReadWriteOnce
  size: 128Mi
  storageClass: "local-storage"
  path: /data

# REDACTED: Sensitive content removed
env:
  - name: CF_API_TOKEN
    valueFrom:
# REDACTED: Sensitive content removed
        name: cloudflare-api-token
# REDACTED: Sensitive content removed

# Additional configuration for routing
additionalResources:
  - apiVersion: v1
    kind: ConfigMap
    metadata:
      name: traefik-config
      namespace: traefik
    data:
      config.yml: |
        http:
          routers:
            rpc:
              rule: "Host(`rpc.1xmr.com`)"
              entryPoints:
                - websecure
              service: rpc
              tls:
                certResolver: letsencrypt
            wallet:
              rule: "Host(`wallet.1xmr.com`)"
              entryPoints:
                - websecure
              service: wallet
              tls:
                certResolver: letsencrypt
            kibana:
              rule: "Host(`kibana.1xmr.com`)"
              entryPoints:
                - websecure
              service: kibana
              tls:
                certResolver: letsencrypt
            elasticsearch:
              rule: "Host(`elasticsearch.1xmr.com`)"
              entryPoints:
                - websecure
              service: elasticsearch
              tls:
                certResolver: letsencrypt
              middlewares:
                - es-auth
            logstash:
              rule: "Host(`logstash.1xmr.com`)"
              entryPoints:
                - websecure
              service: logstash
              tls:
                certResolver: letsencrypt
            traefik-dashboard:
              rule: "Host(`traefik.local`) && PathPrefix(`/dashboard`)"
              entryPoints:
                - websecure
              service: api@internal
              tls:
                certResolver: letsencrypt
          services:
            rpc:
              loadBalancer:
                servers:
                  - url: "http://rpc-service:18082"
                passHostHeader: true
            wallet:
              loadBalancer:
                servers:
                  - url: "http://wallet-service:18081"
                passHostHeader: true
            kibana:
              loadBalancer:
                servers:
                  - url: "http://kibana:5601"
                passHostHeader: true
            elasticsearch:
              loadBalancer:
                servers:
                  - url: "http://elasticsearch-master:9200"
                passHostHeader: true
            logstash:
              loadBalancer:
                servers:
                  - url: "http://logstash:5044"
                passHostHeader: true
          middlewares:
            es-auth:
              basicAuth:
                users:
                  - "admin:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/"

# Logs for troubleshooting
logs:
  general:
    level: DEBUG

=== File: helm/traefik/Chart.yaml ===
apiVersion: v2
name: traefik
description: Traefik Helm chart for Kubernetes
type: application
version: 1.0.0
appVersion: 10.24.0
dependencies:
  - name: traefik
    version: 10.24.0
    repository: https://helm.traefik.io/traefik


=== File: helm/logstash/values.yaml ===
# helm/logstash-values.yaml
image:
  repository: "logstash"
  tag: "7.17.3"

# Resource requests and limits
resources:
  requests:
    cpu: "500m"
    memory: "2Gi"
  limits:
    cpu: "2"
    memory: "4Gi"

# Persistence configuration
persistence:
  enabled: true
  storageClass: "local-storage"
  size: "10Gi"

# Network settings
service:
  type: ClusterIP
  ports:
    - name: http
      port: 5044
      protocol: TCP

# Security settings
securityContext:
  runAsUser: 1000
  fsGroup: 1000

# Logstash configuration
logstashConfig:
  logstash.yml: |
    path.data: /usr/share/logstash/data
    path.logs: /var/log/logstash
    node.name: nextjs-market-logstash
    pipeline.workers: 8
    pipeline.batch.size: 1000
    pipeline.batch.delay: 50
    queue.type: persisted
    queue.max_bytes: 3gb
    log.level: debug

  pipelines.yml: |
    - pipeline.id: main
      path.config: "/usr/share/logstash/pipeline/*.conf"

# JVM options
logstashJavaOpts: "-Xms2g -Xmx2g"

# Pipeline configuration
logstashPipeline:
  nextjs-market.conf: |
    input {
      http {
        host => "0.0.0.0"
        port => 5044
        codec => json
        
        response_headers => {
          "Content-Type" => "application/json"
          "Access-Control-Allow-Origin" => "*"
          "Access-Control-Allow-Methods" => "POST, OPTIONS"
          "Access-Control-Allow-Headers" => "Content-Type"
        }
      }
    }

    filter {
      mutate {
        add_field => {
          "received_at" => "%{@timestamp}"
          "environment" => "${ENVIRONMENT}"
          "service" => "nextjs-market"
          "log_type" => "application"
        }
# REDACTED: Sensitive content removed
      }
    }

    output {
      elasticsearch {
        hosts => ["${ES_HOSTS}"]
        user => "${ES_USER}"
# REDACTED: Sensitive content removed
        index => "nextjs-market-${ENVIRONMENT}-%{+YYYY.MM.dd}"
        ssl_verification_mode => "none"
        timeout => 120
        retry_on_conflict => 5
        retry_max_interval => 30
        retry_initial_interval => 2
      }
      
      file {
        path => "/var/log/logstash/nextjs-market-debug.log"
        codec => json_lines
        flush_interval => 60
      }
    }

# Environment variables
extraEnvs:
  - name: ES_HOSTS
    value: "https://elasticsearch-master:9200"
  - name: ES_USER
    valueFrom:
# REDACTED: Sensitive content removed
        name: logstash-credentials
# REDACTED: Sensitive content removed
# REDACTED: Sensitive content removed
    valueFrom:
# REDACTED: Sensitive content removed
        name: logstash-credentials
# REDACTED: Sensitive content removed
  - name: ENVIRONMENT
    value: "production"


=== File: helm/logstash/Chart.yaml ===
apiVersion: v2
name: logstash
description: Logstash Helm chart for Kubernetes
type: application
version: 1.0.0
appVersion: 7.17.3
dependencies:
  - name: logstash
    version: 7.17.3
    repository: https://helm.elastic.co


=== File: helm/kibana/values.yaml ===
# helm/kibana-values.yaml
image:
  repository: "kibana"
  tag: "7.17.3"

elasticsearchHosts: "http://elasticsearch-master:9200"

# Resource requests and limits
resources:
  requests:
    cpu: "500m"
    memory: "1Gi"
  limits:
    cpu: "1"
    memory: "2Gi"

# Persistence configuration
persistence:
  enabled: true
  storageClass: "local-storage"
  size: "5Gi"

# Network settings
service:
  type: ClusterIP
  port: 5601

# Security settings
securityContext:
  enabled: true
  runAsUser: 1000
  fsGroup: 1000

# Kibana configuration
kibanaConfig:
  kibana.yml: |
    server.host: "0.0.0.0"
    server.publicBaseUrl: "https://kibana.1xmr.com"
    elasticsearch.username: "kibana_admin"
# REDACTED: Sensitive content removed
    elasticsearch.ssl.verificationMode: none
# REDACTED: Sensitive content removed
    logging:
      appenders:
        file:
          type: file
          fileName: /var/log/kibana/kibana.log
          layout:
            type: json
      root:
        appenders:
          - default
          - file
    pid.file: /run/kibana/kibana.pid

# REDACTED: Sensitive content removed
extraEnvs:
# REDACTED: Sensitive content removed
    valueFrom:
# REDACTED: Sensitive content removed
        name: kibana-credentials
# REDACTED: Sensitive content removed
# REDACTED: Sensitive content removed
    valueFrom:
# REDACTED: Sensitive content removed
        name: kibana-credentials
# REDACTED: Sensitive content removed


=== File: helm/kibana/Chart.yaml ===
apiVersion: v2
name: kibana
description: Kibana Helm chart for Kubernetes
type: application
version: 1.0.0
appVersion: 7.17.3
dependencies:
  - name: kibana
    version: 7.17.3
    repository: https://helm.elastic.co


=== File: .github/workflows/build-images.yml ===


